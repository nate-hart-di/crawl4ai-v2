include:
  - ./supabase/docker/docker-compose.yml

volumes:
  ollama_storage:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  caddy-data:
  caddy-config:
  postgres_data:

x-ollama: &service-ollama
  image: ollama/ollama:latest
  container_name: ollama
  restart: unless-stopped
  expose:
    - 11434/tcp
  environment:
    - OLLAMA_CONTEXT_LENGTH=8192
    - OLLAMA_FLASH_ATTENTION=1
    - OLLAMA_KV_CACHE_TYPE=q8_0
    - OLLAMA_MAX_LOADED_MODELS=2
  volumes:
    - ollama_storage:/root/.ollama

x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  container_name: ollama-pull-models
  volumes:
    - ollama_storage:/root/.ollama
  entrypoint: /bin/sh
  command:
    - '-c'
    - 'sleep 3; OLLAMA_HOST=ollama:11434 ollama pull qwen2.5:7b-instruct-q4_K_M; OLLAMA_HOST=ollama:11434 ollama pull nomic-embed-text'

services:
  neo4j:
    image: neo4j:5.15-community
    container_name: neo4j
    restart: unless-stopped
    expose:
      - 7473/tcp
      - 7474/tcp
      - 7687/tcp
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-a4aa05ebe9ef65546509233b6965c960}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    healthcheck:
      test: ['CMD-SHELL', 'wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5

  postgres:
    image: postgres:${POSTGRES_VERSION:-latest}
    container_name: postgres
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 3s
      timeout: 3s
      retries: 10
    expose:
      - 5432/tcp
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data

  crawl4ai-rag:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        PORT: 8051
    container_name: crawl4ai-rag
    restart: unless-stopped
    expose:
      - 8051/tcp
    environment:
      TRANSPORT: sse
      # Local embedding configuration
      USE_LOCAL_EMBEDDINGS: 'true'
      LOCAL_EMBEDDING_MODEL: 'nomic-embed-text:latest'
      MODEL_CHOICE: 'qwen2.5:7b-instruct-q4_K_M'
      OLLAMA_URL: 'http://host.docker.internal:11434'
      # Supabase configuration
      SUPABASE_URL: http://localhost:8000
      SUPABASE_SERVICE_KEY: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Indid2djcWhzYmhqZ2thZnZjcGJkIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0OTgzODgwMSwiZXhwIjoyMDY1NDE0ODAxfQ.rIAOTvLprBFkvNL0bnhpMJHGg71_O179XT8hCWgfb24
      # Knowledge graph configuration
      USE_KNOWLEDGE_GRAPH: 'true'
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: a4aa05ebe9ef65546509233b6965c960
    depends_on:
      - neo4j
      - postgres
      - kong
    volumes:
      - ./knowledge_graphs:/app/knowledge_graphs
      - ./src:/app/src
      - ./shared:/data/shared
    extra_hosts:
      - 'host.docker.internal:host-gateway'

  caddy:
    container_name: caddy
    image: docker.io/library/caddy:2-alpine
    restart: unless-stopped
    ports:
      - 80:80/tcp
      - 443:443/tcp
      - 8001:8001/tcp # Neo4j Browser
      - 8002:8002/tcp # Supabase Studio
      - 8003:8003/tcp # Crawl4AI RAG
      - 8004:8004/tcp # Ollama API
    expose:
      - 2019/tcp
      - 443/tcp
      - 443/udp
      - 80/tcp
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data:rw
      - caddy-config:/config:rw
    environment:
      - NEO4J_HOSTNAME=${NEO4J_HOSTNAME:-":8001"}
      - SUPABASE_HOSTNAME=${SUPABASE_HOSTNAME:-":8002"}
      - CRAWL4AI_HOSTNAME=${CRAWL4AI_HOSTNAME:-":8003"}
      - OLLAMA_HOSTNAME=${OLLAMA_HOSTNAME:-":8004"}
      - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    logging:
      driver: 'json-file'
      options:
        max-size: '1m'
        max-file: '1'

  ollama-cpu:
    profiles: ['cpu']
    <<: *service-ollama

  ollama-gpu:
    profiles: ['gpu-nvidia']
    <<: *service-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  ollama-gpu-amd:
    profiles: ['gpu-amd']
    <<: *service-ollama
    image: ollama/ollama:rocm
    devices:
      - '/dev/kfd'
      - '/dev/dri'

  ollama-pull-models-cpu:
    profiles: ['cpu']
    <<: *init-ollama
    depends_on:
      - ollama-cpu

  ollama-pull-models-gpu:
    profiles: ['gpu-nvidia']
    <<: *init-ollama
    depends_on:
      - ollama-gpu

  ollama-pull-models-gpu-amd:
    profiles: ['gpu-amd']
    <<: *init-ollama
    image: ollama/ollama:rocm
    depends_on:
      - ollama-gpu-amd

networks:
  default:
    name: mcp-network
